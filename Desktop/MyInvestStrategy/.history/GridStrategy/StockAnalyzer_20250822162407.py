import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import plotly.subplots as sp
import plotly.graph_objs as go
from pathlib import Path
import getData
from typing import List, Dict, Any, Tuple, Optional
import os

def int_to_chinese_num(num):
    '''
    è½¬æ¢æ•´æ•°ä¸ºä¸­æ–‡æ•°å­—
    '''
    if not isinstance(num, int):
        return "è¯·è¾“å…¥æ•´æ•°"

    # å¤„ç†è´Ÿæ•°æƒ…å†µ
    sign = ""
    if num < 0:
        sign = "-"
        num = abs(num)

    if num == 0:
        return "é›¶"

    digit_map = ["", "å", "ç™¾", "åƒ"]
    unit_map = ["", "ä¸‡", "äº¿", "å…†"]  # å¯æ‰©å±•æ›´é«˜å•ä½
    num_str = str(num)
    length = len(num_str)
    result = []

    # æ¯4ä½ä¸€ç»„ï¼ˆä¸­æ–‡æ•°å­—ä»¥ä¸‡ä¸ºå•ä½ï¼‰
    for i in range(0, length, 4):
        segment = num_str[max(0, length - i - 4): length - i]
        segment_len = len(segment)
        segment_str = ""

        # å¤„ç†æ¯ä¸€æ®µï¼ˆåƒã€ç™¾ã€åã€ä¸ªä½ï¼‰
        for j in range(segment_len):
            digit = int(segment[j])
            if digit == 0:
                continue  # é›¶ä¸å•ç‹¬æ˜¾ç¤ºï¼Œé™¤éåœ¨ä¸­é—´ï¼ˆå¦‚ 1001 â†’ ä¸€åƒé›¶ä¸€ï¼‰
            # æ·»åŠ æ•°å­—å’Œå•ä½ï¼ˆå¦‚ "3" + "ç™¾" â†’ "3ç™¾"ï¼‰
            segment_str += str(digit) + digit_map[segment_len - j - 1]

        # æ·»åŠ æ®µå•ä½ï¼ˆä¸‡ã€äº¿ç­‰ï¼‰
        if segment_str:  # å¦‚æœè¯¥æ®µä¸ä¸ºç©º
            segment_str += unit_map[i // 4]
        result.append(segment_str)

    # æ‹¼æ¥æ‰€æœ‰æ®µï¼ˆä»é«˜åˆ°ä½ï¼‰
    chinese_num = "".join(reversed(result))

    # å¤„ç†è¿ç»­çš„é›¶ï¼ˆå¦‚ "1001" â†’ "ä¸€åƒé›¶ä¸€"ï¼‰
    chinese_num = chinese_num.replace("é›¶é›¶", "é›¶").strip("é›¶")
    
    # åŠ ä¸Šç¬¦å·ï¼ˆå¦‚æœæ˜¯è´Ÿæ•°ï¼‰
    return sign + chinese_num if chinese_num else "é›¶"

def to_numeric_df(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    """å°†æŒ‡å®šåˆ—è½¬ä¸ºæ•°å€¼ï¼Œéæ³•å€¼ç½®ä¸º NaNã€‚"""
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

# è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
class StockAnalyzer:
    '''
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    '''
    def __init__(self, ticker, file_path, start_date=None, end_date=None, kdj_days = 9, kdj_m1=3, kdj_m2=3, windows = [20, 30, 60, 120]):
        self.ticker = ticker
        self.file_path = file_path
        self.end_date = pd.to_datetime(end_date or datetime.now().strftime('%Y-%m-%d'))
        self.start_date = pd.to_datetime(start_date or (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d'))
        self.stock_data = self.get_data()
        self.windows = windows # å‡çº¿çª—å£

        self.data_ma = {}
        self.data_bbi = {}
        self.data_price = {}
        self.data_macd = {}
        self.data_kdj = {}
        self.data_shakeout = {}

        self.kdj_days = kdj_days
        self.kdj_m1 = kdj_m1
        self.kdj_m2 = kdj_m2
    
    def get_data(self):
        path = Path(self.file_path)
        if not path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶{path}ä¸å­˜åœ¨")
        try:
            data = pd.read_csv(self.file_path, engine=None)
            data['æ—¥æœŸ'] = pd.to_datetime(data['æ—¥æœŸ'])
            start_date = pd.to_datetime(self.start_date)
            end_date = pd.to_datetime(self.end_date)
            data = data[(data['æ—¥æœŸ'] >= start_date) & (data['æ—¥æœŸ'] <= end_date)]
            return data
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶{path}å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{e}")
        return pd.read_csv(path, encoding="utf-8")

    def calculate_all_indicators(self):
        self.calculate_moving_averages()
        self.calculate_bbi()
        self.calculate_price()
        self.calculate_macd()
        self.calculate_kdj()
        self.calculate_shakeout()

    def calculate_kdj(self):
        df = self.stock_data.copy()
        # ä½¿ç”¨ datetime æ¯”è¾ƒ
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df[(df['æ—¥æœŸ'] >= self.start_date) & (df['æ—¥æœŸ'] <= self.end_date)]
        df['high_kdj'] = df['æœ€é«˜'].rolling(window = self.kdj_days, min_periods = 1).max()
        df['low_kdj'] = df['æœ€ä½'].rolling(window = self.kdj_days, min_periods = 1).min()
        df['RSV'] = (df['æ”¶ç›˜'] - df['low_kdj']) / (df['high_kdj'] - df['low_kdj']) * 100
        df['K'] = df['RSV'].ewm(alpha=1/self.kdj_m1, adjust=False).mean()
        df['D'] = df['K'].ewm(alpha=1/self.kdj_m2, adjust=False).mean()
        df['J'] = 3 * df['K'] - 2 * df['D']

        data_list = df[['æ—¥æœŸ','J', 'æ”¶ç›˜', 'æœ€ä½', 'æœ€é«˜']].to_numpy().tolist()
        # å®šä¹‰åŒºé—´é˜ˆå€¼å’Œç­›é€‰å‡½æ•°
        thresholds = {
            'low_0': lambda j: j <= 0,
            'low_5': lambda j: j <= -5,
            'low_10': lambda j: j <= -10,
            'low_15': lambda j: j <= -15,
            'low_20': lambda j: j <= -20,
            'low_25': lambda j: j <= -25,
            'high_80': lambda j: j >= 80,
            'high_90': lambda j: j >= 90,
            'high_100': lambda j: j >= 100,
            'high_110': lambda j: j >= 110,
            'high_120': lambda j: j >= 120,
        }
        fast_down_j_label = False
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        ret_kdj_dict = {key: [] for key in thresholds}

        # éå†æ¯ä¸€è¡Œæ•°æ®
        for row in data_list:
            date, j_val, close, high, low = row[0], float(row[1]), row[2], row[3], row[4]
            row_data = [date, round(j_val, 3), close, high, low]

            for key, condition in thresholds.items():
                if condition(j_val):
                    ret_kdj_dict[key].append(row_data)

        # ç­›é€‰ä¸‰å¤©å†…Jå¿«é€Ÿä¸‹é™
        if data_list[-1][1] < 10 and data_list[-3][1] > 80:
            fast_down_j_label = True
        # æ•´ç†ä¸ºåˆ—è¡¨ï¼ˆæŒ‰ thresholds çš„é¡ºåºï¼‰
        ret_kdj = [ret_kdj_dict[key] for key in thresholds]

        # è¿”å›ç»“æ„åŒ–ç»“æœ
        return {
            'K': df['K'],
            'D': df['D'],
            'J': df['J'],
            'ret_kdj': ret_kdj,
            'fast_down_j_label': fast_down_j_label
        }
    # è®¡ç®—RSI
    def calculate_rsi(self):
        df = self.stock_data.copy()
        # ä½¿ç”¨ datetime æ¯”è¾ƒ
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df[(df['æ—¥æœŸ'] >= self.start_date) & (df['æ—¥æœŸ'] <= self.end_date)]

        delta = df['æ”¶ç›˜'].diff(1)
        gain = (delta.where(delta > 0, 0)).rolling(window=6).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=6).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        df['RSI'] = rsi
        return df
    # è®¡ç®—RSIåŠ¨é‡
    def calculate_rsi_momentum(mom_len: int = 5, method: str = "roc") -> pd.Series:
        """
        RSI åŠ¨é‡ï¼šå¯¹ RSI å†åšåŠ¨é‡ï¼ˆROC æˆ–å·®åˆ†ï¼‰
        method: 'roc' -> (RSI/RSI_{t-m}-1); 'diff' -> RSI - RSI_{t-m}
        """
        r = StockAnalyzer.calculate_rsi()
        if method == "roc":
            out = r / r.shift(mom_len) - 1.0
        elif method == "diff":
            out = r - r.shift(mom_len)
        else:
            raise ValueError("method must be 'roc' or 'diff'")
        return out
    # è®¡ç®—ä»·æ ¼åŠ¨é‡
    def momentum(series: pd.Series, n: int = 10, method: str = "roc") -> pd.Series:
        """
        ä»·æ ¼åŠ¨é‡ï¼š
        method: 
        - 'roc'  -> (P / P_{t-n} - 1)   ç™¾åˆ†æ¯”åŠ¨é‡
        - 'diff' -> (P - P_{t-n})       å·®å€¼åŠ¨é‡
        """
        s = pd.to_numeric(series, errors="coerce")
        if method == "roc":
            return s / s.shift(n) - 1.0
        elif method == "diff":
            return s - s.shift(n)
        else:
            raise ValueError("method must be 'roc' or 'diff'")

    def calculate_moving_averages(self):
        windows = self.windows
        result = {}
        for window in windows:
            result[f'MA_{window}'] = self.stock_data['æ”¶ç›˜'].rolling(window=window).mean()
        result['date'] = self.stock_data['æ—¥æœŸ']
        self.data_ma = pd.DataFrame(result)
        return self.data_ma

    def calculate_bbi(self):
        data = self.stock_data.copy()
        data['avg_price'] = (data['æ”¶ç›˜'] + data['æœ€é«˜'] + data['æœ€ä½']) / 3
        data['ma3'] = data['avg_price'].rolling(3).mean()
        data['ma6'] = data['avg_price'].rolling(6).mean()
        data['ma12'] = data['avg_price'].rolling(12).mean()
        data['ma24'] = data['avg_price'].rolling(24).mean()
        data['bbi'] = (data['ma3'] + data['ma6'] + data['ma12'] + data['ma24']) / 4
        return {'date': data['æ—¥æœŸ'], 'bbi': data['bbi']}

    def calculate_price(self):
        data = self.stock_data.copy()
        data['avg_price'] = (data['æ”¶ç›˜'] + data['æœ€é«˜'] + data['æœ€ä½']) / 3
        data['close_price'] = data['æ”¶ç›˜']
        data['open_price'] = data['å¼€ç›˜']
        return {'date': data['æ—¥æœŸ'], 'avg_price': data['avg_price'], 'close_price': data['close_price'], 'open_price':data['open_price']}

    def calculate_macd(self, fast=12, slow=26, signal=9):
        df = self.stock_data.copy()
        ema_fast = df['æ”¶ç›˜'].ewm(span=fast, adjust=False).mean()
        ema_slow = df['æ”¶ç›˜'].ewm(span=slow, adjust=False).mean()
        dif = ema_fast - ema_slow
        dea = dif.ewm(span=signal, adjust=False).mean()
        macd = (dif - dea) * 2
        return {'date': df['æ—¥æœŸ'], 'DIF': dif, 'DEA': dea, 'MACD': macd}

    def calculate_shakeout(self):
        '''
        | æŒ‡æ ‡åç§°       | æ¡ä»¶                  | å«ä¹‰è§£é‡Š              |
        | ---------- | ------------------- | ----------------- |
        | **å››çº¿å½’é›¶ä¹°**  | çŸ­æœŸã€ä¸­æœŸã€ä¸­é•¿æœŸã€é•¿æœŸéƒ½ <= 6  | å››ä¸ªæŒ‡æ ‡éƒ½è¶…å–ï¼Œæç«¯ä½ç‚¹ï¼Œå¯èƒ½åå¼¹ |
        | **ç™½çº¿ä¸‹20ä¹°** | çŸ­æœŸ <= 20 ä¸” é•¿æœŸ >= 60 | çŸ­æœŸè¶…å–ï¼Œé•¿æœŸä»å¼ºï¼Œå¯èƒ½æ˜¯å›è°ƒä¹°ç‚¹ |
        | **ç™½ç©¿çº¢çº¿ä¹°**  | çŸ­æœŸä¸Šç©¿é•¿æœŸ ä¸” é•¿æœŸ < 20    | åŠ¨é‡é‡‘å‰ä¸”ä½ä½ï¼Œåè½¬å¯èƒ½æ€§å¤§    |
        | **ç™½ç©¿é»„çº¿ä¹°**  | çŸ­æœŸä¸Šç©¿ä¸­æœŸ ä¸” ä¸­æœŸ < 30    | åŠ¨é‡æ‹å¤´ï¼Œåˆæ­¥åå¼¹ä¿¡å·       |
        '''
        N1 = 3 # çŸ­æœŸæŒ‡æ ‡
        N2 = 21 # é•¿æœŸæŒ‡æ ‡
        df = self.stock_data.copy()
        #df = df[(df['æ—¥æœŸ'] >= str(self.start_date)) & (df['æ—¥æœŸ'] <= str(self.end_date))]


        # è®¡ç®—å‡½æ•°
        def momentum_indicator(C, L, n):
            return 100 * (C - L.rolling(n).min()) / (C.rolling(n).max() - L.rolling(n).min())

        # è®¡ç®—çŸ­ä¸­é•¿æœŸæŒ‡æ ‡
        df['çŸ­æœŸ'] = momentum_indicator(df['æ”¶ç›˜'], df['æœ€ä½'], N1)
        df['ä¸­æœŸ'] = momentum_indicator(df['æ”¶ç›˜'], df['æœ€ä½'], 10)
        df['ä¸­é•¿æœŸ'] = momentum_indicator(df['æ”¶ç›˜'], df['æœ€ä½'], 20)
        df['é•¿æœŸ'] = momentum_indicator(df['æ”¶ç›˜'], df['æœ€ä½'], N2)

        # ä¹°ç‚¹æ¡ä»¶
        df['å››çº¿å½’é›¶ä¹°'] = np.where(
            (df['çŸ­æœŸ'] <= 6) & (df['ä¸­æœŸ'] <= 6) & (df['ä¸­é•¿æœŸ'] <= 6) & (df['é•¿æœŸ'] <= 6),
            1, 0)

        df['ç™½çº¿ä¸‹20ä¹°'] = np.where(
            (df['çŸ­æœŸ'] <= 20) & (df['é•¿æœŸ'] >= 80),
            1, 0)

        df['ç™½çº¿ä¸‹20ä¹°_å°V'] = np.where(
            (df['é•¿æœŸ'] - df['çŸ­æœŸ'] >= 40) & (df['é•¿æœŸ'] >= 60),
            1, 0)

        # ç™½ç©¿çº¢çº¿ä¹°ï¼ˆé‡‘å‰ï¼‰
        df['ç™½ç©¿çº¢çº¿ä¹°'] = np.where(
            (df['çŸ­æœŸ'] > df['é•¿æœŸ']) & (df['çŸ­æœŸ'].shift(1) <= df['é•¿æœŸ'].shift(1)) & (df['é•¿æœŸ'] < 20),
            1, 0)

        # ç™½ç©¿é»„çº¿ä¹°ï¼ˆé‡‘å‰ï¼‰
        df['ç™½ç©¿é»„çº¿ä¹°'] = np.where(
            (df['çŸ­æœŸ'] > df['ä¸­æœŸ']) & (df['çŸ­æœŸ'].shift(1) <= df['ä¸­æœŸ'].shift(1)) & (df['ä¸­æœŸ'] < 30),
            1, 0)

        # è¾“å‡ºæœ€åå‡ è¡ŒæŸ¥çœ‹
        #print(df[['çŸ­æœŸ', 'ä¸­æœŸ', 'ä¸­é•¿æœŸ', 'é•¿æœŸ', 'å››çº¿å½’é›¶ä¹°', 'ç™½çº¿ä¸‹20ä¹°', 'ç™½ç©¿çº¢çº¿ä¹°', 'ç™½ç©¿é»„çº¿ä¹°']].tail())

        return df
    # è®¡ç®—ATR
    def rolling_atr_pct(df: pd.DataFrame, n: int = 14) -> pd.Series:
        """
        è®¡ç®— ATR% = ATR / Closeï¼Œä½¿ç”¨ç®€å•å‡å€¼ï¼ˆéWilderï¼‰ï¼Œåæ˜ ä»·æ ¼æ³¢åŠ¨å¹…åº¦ã€‚
        TR = max(high-low, |high-prev_close|, |low-prev_close|)
        """
        h = df["æœ€é«˜"].values
        l = df["æœ€ä½"].values
        c = df["æ”¶ç›˜"].values
        pc = np.r_[np.nan, c[:-1]]
        tr = np.maximum.reduce([h - l, np.abs(h - pc), np.abs(l - pc)])
        atr = pd.Series(tr).rolling(n, min_periods=n).mean()
        return atr / df["æ”¶ç›˜"]
    # è®¡ç®—å¸ƒæ—å¸¦è´·æ¬¾
    def boll_bandwidth(df: pd.DataFrame, n: int = 20, k: float = 2.0) -> pd.Series:
        """
        å¸ƒæ—å¸¦å¸¦å®½ï¼š (Upper - Lower) / Middle, å…¶ä¸­ Upper/Lower = MA Â± k*STD
        """
        mid = df["æ”¶ç›˜"].rolling(n, min_periods=n).mean()
        std = df["æ”¶ç›˜"].rolling(n, min_periods=n).std()
        upper = mid + k * std
        lower = mid - k * std
        return (upper - lower) / mid
    # è®¡ç®—zigzag
    def percent_zigzag(high: np.ndarray,
                    low: np.ndarray,
                    pct: float = 0.05) -> List[Dict[str, Any]]:
        """
        ç™¾åˆ†æ¯” ZigZagï¼ˆä½¿ç”¨ high/low æ•æ‰æå€¼ï¼‰ã€‚
        å½“ä»å½“å‰æå€¼å‘ç›¸åæ–¹å‘åè½¬å¹…åº¦ >= pct å³ç¡®è®¤æ‹ç‚¹ã€‚
        è¿”å›æŒ‰æ—¶é—´æ’åºçš„ pivot åˆ—è¡¨ï¼š
        [{'idx': i, 'type': 'peak'/'trough', 'price': price}, ...]
        """
        n = len(high)
        if n == 0:
            return []
        pivots: List[Dict[str, Any]] = []
        direction = 0
        up_max, up_i = high[0], 0
        dn_min, dn_i = low[0], 0

        for i in range(1, n):
            if high[i] > up_max:
                up_max, up_i = high[i], i
            if low[i] < dn_min:
                dn_min, dn_i = low[i], i

            if direction >= 0:
                if (up_max - low[i]) / max(up_max, 1e-12) >= pct:
                    pivots.append({"idx": int(up_i), "type": "peak", "price": float(up_max)})
                    direction = -1
                    dn_min, dn_i = low[i], i
            if direction <= 0:
                if (high[i] - dn_min) / max(dn_min, 1e-12) >= pct:
                    pivots.append({"idx": int(dn_i), "type": "trough", "price": float(dn_min)})
                    direction = 1
                    up_max, up_i = high[i], i

        pivots.sort(key=lambda x: x["idx"])
        # æ¸…ç†è¿ç»­åŒç±»ï¼Œä¿ç•™æ›´â€œæç«¯â€çš„
        cleaned = []
        for p in pivots:
            if not cleaned:
                cleaned.append(p)
            else:
                if cleaned[-1]["type"] != p["type"]:
                    cleaned.append(p)
                else:
                    if p["type"] == "peak":
                        if p["price"] >= cleaned[-1]["price"]:
                            cleaned[-1] = p
                    else:
                        if p["price"] <= cleaned[-1]["price"]:
                            cleaned[-1] = p
        return cleaned
    # è®¡ç®—VCPå‹ç¼©
    def calculate_vcp(self, col_date: str = "date", col_open: str = "å¼€ç›˜",col_high: str = "æœ€é«˜",col_low: str = "æœ€ä½",col_close: str = "æ”¶ç›˜",col_volume: str = "æˆäº¤é‡",
        # ZigZag & æ”¶ç¼©åˆ¤å®š
        zigzag_pct: float = 0.06,
        min_contractions: int = 2,
        max_contractions: int = 4,
        min_drop: float = 0.06,           # æ¯æ®µå›æ’¤è‡³å°‘ 6%
        tighten_ratio_max: float = 0.85,  # æ”¶ç¼©é€’å‡ï¼šC2 <= C1*0.85
        # å‹ç¼©ï¼ˆåŸºåº•æœŸï¼‰ä¸å¹²æ¶¸
        bb_len: int = 20,
        atr_len: int = 14,
        bw_low_pct: float = 0.35,         # å¸ƒæ—å¸¦å¸¦å®½å†å²ä½åˆ†ä½é˜ˆå€¼
        atr_low_pct: float = 0.35,        # ATR% å†å²ä½åˆ†ä½é˜ˆå€¼
        dryup_days: int = 5,
        vol_ma_len: int = 50,
        dryup_thresh: float = 0.60,       # è¿‘ dryup_days å‡é‡ / MA50 < 0.6
        # æ¢è½´/çªç ´/å†æ‰©å¼ 
        near_pivot_tol: float = 0.03,     # ç°ä»·åœ¨æ¢è½´ä¸‹æ–¹ â‰¤3% è§†ä¸ºâ€œæ¥è¿‘æ¢è½´â€
        breakout_vol_mult: float = 1.5,   # çªç ´æ”¾é‡é˜ˆå€¼ï¼ˆç›¸å¯¹ MA50ï¼‰
        reexpansion_win: int = 3,         # çªç ´é™„è¿‘æœ€è¿‘ N å¤©
        reexpansion_bw_increase: float = 0.20,  # è¿‘Nå¤© å¸¦å®½ >= åŸºåº•ä¸­ä½æ•°*1.20
        reexpansion_atr_increase: float = 0.10, # è¿‘Nå¤© ATR% >= åŸºåº•ä¸­ä½æ•°*1.10
        # èŒƒå›´é™åˆ¶
        window: int = 220                 # åªçœ‹æœ€è¿‘ N æ ¹ï¼Œä¾¿äºåˆ†ä½è®¡ç®—
    ):
        """
        è¯»å– CSV â†’ è®¡ç®— VCP â€œå‹ç¼©â€è¯„åˆ†ã€‚
        å¾—åˆ†æ„æˆï¼ˆæ€»åˆ†=100ï¼‰ï¼š
        1) åŸºåº•å‹ç¼©è´¨é‡ï¼šå¸ƒæ—å¸¦ 20 + ATR% 10 = 30
        2) è¿ç»­æ”¶ç¼©ç»“æ„ï¼š20
        3) é‡èƒ½æ¯ç«­ï¼š15
        4) æ¥è¿‘æ¢è½´ï¼š10
        5) çªç ´æ”¾é‡ï¼š10
        6) å†æ‰©å¼ ï¼ˆçªç ´é™„è¿‘å¸¦å®½/ATR%æŠ¬å‡ï¼‰ï¼š15
        """
        df = self.stock_data.copy()
        df.columns = [c.strip().lower() for c in df.columns]
        rename_map = {}
        for k_std, v_user in {
            "æ—¥æœŸ": col_date, "å¼€ç›˜": col_open, "æœ€é«˜": col_high,
            "æœ€ä½": col_low, "æ”¶ç›˜": col_close, "æˆäº¤é‡": col_volume
        }.items():
            if v_user.lower() in df.columns:
                rename_map[v_user.lower()] = k_std
        df = df.rename(columns=rename_map)

        need = {"å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"}
        if not need.issubset(df.columns):
            return {"ok": False, "message": f"CSV éœ€åŒ…å«åˆ—ï¼š{need}ï¼Œå®é™…åˆ—ï¼š{set(df.columns)}"}

        if "æ—¥æœŸ" in df.columns:
            try:
                df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
            except Exception:
                pass

        for c in ["å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]:
            df[c] = pd.to_numeric(df[c], errors="coerce")
        df = df.dropna(subset=[ "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]).reset_index(drop=True)

        if len(df) < max(bb_len + 5, atr_len + 5, vol_ma_len + 5, 80):
            return {"ok": False, "message": "æ•°æ®é•¿åº¦ä¸è¶³ï¼Œæ— æ³•ç¨³å®šè®¡ç®—ã€‚"}

        # ä»…æˆªå–æœ€è¿‘ window æ ¹
        if window and len(df) > window:
            df = df.iloc[-window:].reset_index(drop=True)

        # â€”â€” æŒ‡æ ‡è®¡ç®— â€”â€”
        df["atr_pct"] = StockAnalyzer.rolling_atr_pct(df, n=atr_len)
        df["bb_bw"] = StockAnalyzer.boll_bandwidth(df, n=bb_len, k=2.0)
        df["vol_ma"] = df["äº¤æ˜“é‡"].rolling(vol_ma_len, min_periods=1).mean()

        # â€”â€” ZigZag æ”¶ç¼©æ®µï¼ˆpeak->troughï¼‰ â€”â€”
        pivots = StockAnalyzer.percent_zigzag(df["æœ€é«˜"].values, df["æœ€ä½"].values, pct=zigzag_pct)
        contractions: List[Dict[str, Any]] = []
        for i in range(len(pivots) - 1):
            a, b = pivots[i], pivots[i + 1]
            if a["type"] == "peak" and b["type"] == "trough" and b["idx"] > a["idx"]:
                drop = (a["price"] - b["price"]) / max(a["price"], 1e-12)
                contractions.append({
                    "peak_idx": a["idx"], "trough_idx": b["idx"],
                    "peak": float(a["price"]), "trough": float(b["price"]),
                    "drop_pct": float(drop)
                })
        if len(contractions) < min_contractions:
            return {"ok": False, "message": "ZigZag æ”¶ç¼©æ®µä¸è¶³ã€‚", "pivots": pivots}

        m = min(max_contractions, len(contractions))
        seg = contractions[-m:]
        drops = [c["drop_pct"] for c in seg]

        base_start = seg[0]["peak_idx"]
        base_end   = seg[-1]["trough_idx"]
        if base_end <= base_start:
            return {"ok": False, "message": "åŸºåº•åŒºé—´éæ³•ã€‚"}

        # â€”â€” 1) è¿ç»­æ”¶ç¼©ç»“æ„ â€”â€” 
        contraction_ok = True
        if any(d < min_drop for d in drops):
            contraction_ok = False
        for j in range(len(drops) - 1):
            if drops[j + 1] > drops[j] * tighten_ratio_max:
                contraction_ok = False
                break

        # â€”â€” 2) åŸºåº•å‹ç¼©è´¨é‡ï¼ˆä½åˆ†ä½ï¼‰â€”â€”
        base_bw = df.loc[base_start:base_end, "bb_bw"].dropna()
        hist_bw = df["bb_bw"].dropna()
        base_atr = df.loc[base_start:base_end, "atr_pct"].dropna()
        hist_atr = df["atr_pct"].dropna()

        bw_ok = atr_ok = False
        bw_med = atr_med = np.nan
        bw_q = atr_q = np.nan
        if len(base_bw) and len(hist_bw):
            bw_med = float(np.nanmedian(base_bw.values))
            bw_q   = float(np.nanpercentile(hist_bw.values, bw_low_pct * 100))
            bw_ok  = (bw_med <= bw_q)
        if len(base_atr) and len(hist_atr):
            atr_med = float(np.nanmedian(base_atr.values))
            atr_q   = float(np.nanpercentile(hist_atr.values, atr_low_pct * 100))
            atr_ok  = (atr_med <= atr_q)

        # â€”â€” 3) é‡èƒ½æ¯ç«­ â€”â€” 
        tail = df.loc[max(base_end - dryup_days + 1, 0):base_end]
        vol_ma_ref = float(df.loc[:base_end, "vol_ma"].iloc[-1])
        dryup_ratio = float(tail["volume"].mean() / max(vol_ma_ref, 1e-9))
        dryup_ok = (dryup_ratio < dryup_thresh)

        # â€”â€” 4) æ¢è½´/æ¥è¿‘æ¢è½´ â€”â€” 
        pivot_idx = seg[-1]["peak_idx"]
        pivot_price = float(df.loc[pivot_idx, "æœ€é«˜"])
        last_close = float(df["close"].iloc[-1])
        dist_to_pivot = (pivot_price - last_close) / max(pivot_price, 1e-9)  # >0 è¡¨ç¤ºåœ¨æ¢è½´ä¸‹æ–¹
        near_pivot = (0 <= dist_to_pivot <= near_pivot_tol)

        # â€”â€” 5) çªç ´ + æ”¾é‡ â€”â€” 
        breakout = (last_close > pivot_price * (1 + 1e-4))
        breakout_vol_ok = False
        if breakout:
            breakout_vol_ok = (df["äº¤æ˜“é‡"].iloc[-1] > breakout_vol_mult * df["vol_ma"].iloc[-1])

        # â€”â€” 6) å†æ‰©å¼ ï¼ˆçªç ´é™„è¿‘å¸¦å®½/ATR% ä»åŸºåº•ä¸­ä½æ•°å›å‡ï¼‰â€”â€”
        recent_bw  = float(df["bb_bw"].tail(reexpansion_win).mean())
        recent_atr = float(df["atr_pct"].tail(reexpansion_win).mean())
        bw_reexp_ok  = (not np.isnan(bw_med))  and (recent_bw  >= bw_med  * (1.0 + reexpansion_bw_increase))
        atr_reexp_ok = (not np.isnan(atr_med)) and (recent_atr >= atr_med * (1.0 + reexpansion_atr_increase))
        reexpansion_ok = bool(breakout and (bw_reexp_ok or atr_reexp_ok))

        # -------------------- æ‰“åˆ†ï¼ˆæ€»åˆ† 100ï¼‰ --------------------
        # 1) åŸºåº•å‹ç¼©ï¼ˆ30ï¼‰
        score_bw   = 20.0 if bw_ok  else 0.0
        score_atr  = 10.0 if atr_ok else 0.0
        score_comp = score_bw + score_atr

        # 2) è¿ç»­æ”¶ç¼©ç»“æ„ï¼ˆ20ï¼‰
        score_contraction = 0.0
        if contraction_ok:
            avg_drop = float(np.mean(drops))         # å¹³å‡å›æ’¤(ä½œä¸ºåŠ›åº¦å‚è€ƒ)
            drop_score = min(1.0, avg_drop / 0.15)   # 15% é¥±å’Œ
            tighten_bonus = 1.0                      # é€šè¿‡å³æ»¡ï¼ˆç»“æ„æ€§ï¼‰
            score_contraction = 20.0 * (0.6 * drop_score + 0.4 * tighten_bonus)

        # 3) å¹²æ¶¸ï¼ˆ15ï¼‰
        dryup_score = max(0.0, min(1.0, (0.6 - dryup_ratio) / 0.6))  # ratio<=0.6 å¾—æ»¡åˆ†
        score_dryup = 15.0 * dryup_score

        # 4) æ¥è¿‘æ¢è½´ï¼ˆ10ï¼‰
        score_near = 0.0
        if near_pivot:
            score_near = 10.0 * max(0.0, min(1.0, (near_pivot_tol - dist_to_pivot) / max(near_pivot_tol, 1e-9)))

        # 5) çªç ´æ”¾é‡ï¼ˆ10ï¼‰
        score_breakout = 10.0 if (breakout and breakout_vol_ok) else 0.0

        # 6) å†æ‰©å¼ ï¼ˆ15ï¼‰
        score_reexp = 15.0 if reexpansion_ok else 0.0

        total_score = round(score_comp + score_contraction + score_dryup + score_near + score_breakout + score_reexp, 3)

        # -------------------- è¾“å‡º --------------------
        out = {
            "ok": True,
            "message": "success",
            "score": total_score,
            "score_breakdown": {
                "compression_bw": round(score_bw, 3),
                "compression_atr": round(score_atr, 3),
                "contraction": round(score_contraction, 3),
                "dryup": round(score_dryup, 3),
                "near_pivot": round(score_near, 3),
                "breakout": round(score_breakout, 3),
                "reexpansion": round(score_reexp, 3),
            },
            "flags": {
                "contraction_ok": bool(contraction_ok),
                "bw_low_ok": bool(bw_ok),
                "atr_low_ok": bool(atr_ok),
                "dryup_ok": bool(dryup_ok),
                "near_pivot": bool(near_pivot),
                "breakout": bool(breakout),
                "breakout_vol_ok": bool(breakout_vol_ok),
                "reexpansion_ok": bool(reexpansion_ok),
                "bw_reexp_ok": bool(bw_reexp_ok),
                "atr_reexp_ok": bool(atr_reexp_ok),
            },
            "components": {
                "drops": [round(d, 6) for d in drops],
                "avg_drop": float(np.mean(drops)),
                "pivot_price": round(pivot_price, 6),
                "last_close": round(last_close, 6),
                "dist_to_pivot": round(dist_to_pivot, 6),
                "dryup_ratio": round(dryup_ratio, 6),
                "base_bw_median": float(bw_med) if not np.isnan(bw_med) else None,
                "base_atr_median": float(atr_med) if not np.isnan(atr_med) else None,
                "hist_bw_pct_threshold": float(bw_q) if not np.isnan(bw_q) else None,
                "hist_atr_pct_threshold": float(atr_q) if not np.isnan(atr_q) else None,
                "recent_bw": recent_bw,
                "recent_atr": recent_atr,
            },
            "pivots_tail": pivots[-12:],  # ä¾¿äºå®¡é˜…
            "params": {
                "zigzag_pct": zigzag_pct,
                "min_drop": min_drop,
                "tighten_ratio_max": tighten_ratio_max,
                "bb_len": bb_len,
                "atr_len": atr_len,
                "bw_low_pct": bw_low_pct,
                "atr_low_pct": atr_low_pct,
                "dryup_days": dryup_days,
                "vol_ma_len": vol_ma_len,
                "dryup_thresh": dryup_thresh,
                "near_pivot_tol": near_pivot_tol,
                "breakout_vol_mult": breakout_vol_mult,
                "reexpansion_win": reexpansion_win,
                "reexpansion_bw_increase": reexpansion_bw_increase,
                "reexpansion_atr_increase": reexpansion_atr_increase,
                "window": window
            }
        }
        return out

    # è®¡ç®—å‡çº¿ç»“æ„
    def evaluate_ma_structure(
        close: pd.Series,
        windows: Tuple[int, ...] = (5, 10, 20, 50, 60),
        slope_lookback: int = 3,           # ä»ç”¨äºâ€œæ‰€æœ‰MAä¸Šè¡Œâ€åˆ¤å®š
        max_extension: Optional[float] = 0.12,
        # â€”â€” ä½ç‚¹æŠ¬é«˜å‚æ•° â€”â€”
        use_low_series: Optional[pd.Series] = None,  # å»ºè®®ä¼ å…¥ lowï¼›ä¸ä¼ åˆ™ç”¨ close
        hl_lookaround: int = 3,   # æ‘†åŠ¨ä½ç‚¹çª—å£åŠå®½
        hl_count: int = 3         # è‡³å°‘æœ€è¿‘ hl_count ä¸ªæ‘†åŠ¨ä½ç‚¹ä¾æ¬¡æŠ¬é«˜
    ) -> Dict[str, Any]:
        """
        æ‰©å±•ç‰ˆâ€œä¼˜ç§€å‡çº¿ç»“æ„â€è¯„åˆ†ï¼ˆæ€»åˆ†=100ï¼‰ï¼š
        ä»·æ ¼åœ¨å‡çº¿ä¸Šæ–¹ï¼š20
        å‡çº¿ä¸¥æ ¼å¤šå¤´æ’åˆ—ï¼š30
        å‡çº¿æ•´ä½“ä¸Šè¡Œï¼ˆæ‰€æœ‰MAï¼‰ï¼š20
        MA5 ä¸¥æ ¼æŠ¬å¤´ï¼ˆè§ä¸‹è¿°åŒæ¡ä»¶ï¼‰ï¼š15
        ä½ç‚¹ä¸æ–­æŠ¬é«˜ï¼š15
        ä¸è¿‡åº¦ä¹–ç¦»ï¼š5

        MA5 ä¸¥æ ¼æŠ¬å¤´ï¼ˆå¿…é¡»åŒæ—¶æ»¡è¶³ï¼‰ï¼š
        1) MA5[t] > MA5[t-1]
        2) (MA5[t]-MA5[t-3]) > (MA5[t-3]-MA5[t-6])
        """
        # â€”â€” æ•°æ®å‡†å¤‡ â€”â€”
        s = pd.to_numeric(close, errors="coerce")
        if 5 not in windows:
            windows = tuple(sorted(set((5,) + tuple(windows))))  # å¼ºåˆ¶åŒ…å«MA5
        ma: Dict[int, pd.Series] = {w: s.rolling(w, min_periods=w).mean() for w in windows}
        last = s.iloc[-1]

        # â€”â€” ä»·æ ¼åœ¨å…¨éƒ¨ MA ä¹‹ä¸Š â€”â€”
        above_all = all(
            (not pd.isna(ma[w].iloc[-1])) and (last > ma[w].iloc[-1])
            for w in windows
        )

        # â€”â€” å¤šå¤´æ’åˆ—ï¼ˆä¸¥æ ¼ï¼šçŸ­ > é•¿ï¼‰ â€”â€”
        ordered = True
        last_vals: List[float] = []
        for w in windows:
            v = ma[w].iloc[-1]
            if pd.isna(v):
                ordered = False
                break
            last_vals.append(v)
        if ordered:
            ordered = all(last_vals[i] > last_vals[i+1] for i in range(len(last_vals)-1))

        # â€”â€” æ‰€æœ‰ MA ä¸Šè¡Œï¼šMA[-1] > MA[-1 - slope_lookback] â€”â€”
        slopes_ok = True
        for w in windows:
            series = ma[w]
            if len(series) <= slope_lookback or pd.isna(series.iloc[-1]) or pd.isna(series.iloc[-1 - slope_lookback]):
                slopes_ok = False
                break
            if series.iloc[-1] <= series.iloc[-1 - slope_lookback]:
                slopes_ok = False
                break

        # â€”â€” MA5 ä¸¥æ ¼æŠ¬å¤´ï¼ˆä»Šå¤©>æ˜¨å¤© & è¿‘3æ—¥æ–œç‡>å‰3æ—¥æ–œç‡ï¼‰ â€”â€”
        ma5 = ma[5]
        ma5_turning_strict = False
        ma5_today = ma5.iloc[-1] if len(ma5) > 0 else np.nan
        ma5_yest  = ma5.iloc[-2] if len(ma5) > 1 else np.nan
        slope_recent_3 = np.nan
        slope_prev_3   = np.nan
        if len(ma5) >= 7 and not any(pd.isna([ma5_today, ma5_yest])):
            slope_recent_3 = ma5.iloc[-1] - ma5.iloc[-4]  # t - (t-3)
            slope_prev_3   = ma5.iloc[-4] - ma5.iloc[-7]  # (t-3) - (t-6)
            ma5_turning_strict = (ma5_today > ma5_yest) and (slope_recent_3 > slope_prev_3)

        # â€”â€” ä½ç‚¹ä¸æ–­æŠ¬é«˜ï¼ˆæ‘†åŠ¨ä½ç‚¹ï¼‰ â€”â€”
        base_series = pd.to_numeric(use_low_series, errors="coerce") if use_low_series is not None else s
        swing_low_idx: List[int] = []
        swing_low_val: List[float] = []
        for i in range(hl_lookaround, len(base_series) - hl_lookaround):
            win = base_series.iloc[i - hl_lookaround:i + hl_lookaround + 1]
            # å½“å‰ç‚¹æ—¢æ˜¯çª—å£æœ€å°å€¼ä¸”ä½äºä¸­å¿ƒï¼ˆé€šè¿‡ idxmin æ ¡éªŒï¼‰
            if base_series.iloc[i] == win.min() and win.idxmin() == base_series.index[i]:
                swing_low_idx.append(i)
                swing_low_val.append(float(base_series.iloc[i]))

        higher_lows_ok = False
        higher_lows_used: List[float] = []
        if len(swing_low_val) >= hl_count:
            last_lows = swing_low_val[-hl_count:]
            higher_lows_ok = all(last_lows[j] < last_lows[j+1] for j in range(len(last_lows)-1))
            higher_lows_used = last_lows

        # â€”â€” ä¹–ç¦»ä¸è¿‡åº¦ï¼ˆç›¸å¯¹æœ€çŸ­å‡çº¿ï¼‰ â€”â€”
        not_overextended = True
        ext_ratio = np.nan
        if max_extension is not None:
            short_w = min(windows)
            short_ma = ma[short_w].iloc[-1]
            if pd.isna(short_ma) or short_ma == 0:
                not_overextended = False
            else:
                ext_ratio = abs(last / short_ma - 1.0)
                not_overextended = (ext_ratio <= max_extension)

        # â€”â€” æ‰“åˆ†ï¼ˆæ€»åˆ† 100ï¼‰ â€”â€”
        score = 0.0
        score += 20 if above_all else 0
        score += 30 if ordered else 0
        score += 20 if slopes_ok else 0
        score += 15 if ma5_turning_strict else 0
        score += 15 if higher_lows_ok else 0
        score += 5  if not_overextended else 0

        return {
            "score": round(score, 2),
            "flags": {
                "above_all": bool(above_all),
                "ordered": bool(ordered),
                "slopes_ok": bool(slopes_ok),
                "ma5_turning_strict": bool(ma5_turning_strict),
                "higher_lows_ok": bool(higher_lows_ok),
                "not_overextended": bool(not_overextended),
            },
            "latest": {
                "close": float(last),
                **{f"ma{w}": float(ma[w].iloc[-1]) if not pd.isna(ma[w].iloc[-1]) else np.nan for w in windows},
                "extension_vs_ma_short": float(ext_ratio) if not np.isnan(ext_ratio) else None,
                "higher_lows_used": higher_lows_used,
                "ma5_today": float(ma5_today) if not pd.isna(ma5_today) else None,
                "ma5_yesterday": float(ma5_yest) if not pd.isna(ma5_yest) else None,
                "ma5_slope_recent_3": float(slope_recent_3) if not pd.isna(slope_recent_3) else None,
                "ma5_slope_prev_3": float(slope_prev_3) if not pd.isna(slope_prev_3) else None,
            },
            "params": {
                "windows": windows,
                "slope_lookback": slope_lookback,
                "max_extension": max_extension,
                "use_low_series": "low" if use_low_series is not None else "close",
                "hl_lookaround": hl_lookaround,
                "hl_count": hl_count,
                "ma5_turning_rule": "MA5[t]>MA5[t-1] and (MA5[t]-MA5[t-3])>(MA5[t-3]-MA5[t-6])",
            }
        }
    
    # è®¡ç®—RS
    def compute_rs(stock_close: pd.Series, bench_close: pd.Series) -> pd.Series:
        """
        RS çº¿ï¼šä¸ªè‚¡ / åŸºå‡†ï¼ˆè‡ªåŠ¨å¯¹é½ç´¢å¼•å¹¶å‰å‘å¡«å……åŸºå‡†ç¼ºå£ï¼‰
        """
        sc = pd.to_numeric(stock_close, errors="coerce")
        bc = pd.to_numeric(bench_close, errors="coerce")
        df = pd.concat({"s": sc, "b": bc}, axis=1).sort_index().dropna(how="all")
        df["b"] = df["b"].ffill()
        rs = df["s"] / df["b"].replace(0, np.nan)
        return rs
    
    # è®¡ç®—RSç»“æ„
    def evaluate_rs_structure(
        stock_close: pd.Series,
        bench_close: pd.Series,
        windows: Tuple[int, ...] = (20, 50, 100),
        slope_lookback: int = 3,
        nhigh_lookback: int = 60,
    ) -> Dict[str, Any]:
        """
        RS ç»“æ„ï¼ˆç›¸å¯¹å¼ºäºå¤§ç›˜/è¡Œä¸šï¼‰ï¼š
        - RS åœ¨å…¶å‡çº¿ä¸Šæ–¹
        - RS çš„å‡çº¿å¤šå¤´æœ‰åº & ä¸Šè¡Œ
        - RS åˆ›å‡ºè¿‘ nhigh_lookback é«˜ç‚¹ï¼ˆå¯é€‰ï¼ŒåŠ åˆ†ï¼‰

        è¯„åˆ†ï¼ˆæ€»åˆ†100ï¼‰ï¼š
        RS åœ¨å‡çº¿ä¸Šæ–¹ï¼š30
        RS å‡çº¿å¤šå¤´æ’åˆ—ï¼š40
        RS å‡çº¿ä¸Šè¡Œï¼š20
        RS æ¥è¿‘/çªç ´è¿‘é«˜ï¼š10
        """
        rs = StockAnalyzer.compute_rs(stock_close, bench_close)
        ma = {w: rs.rolling(w, min_periods=w).mean() for w in windows}
        last = rs.iloc[-1]

        above_all = all(last > ma[w].iloc[-1] for w in windows if not pd.isna(ma[w].iloc[-1]))

        ordered = True
        last_vals = []
        for w in windows:
            v = ma[w].iloc[-1]
            if pd.isna(v):
                ordered = False
                break
            last_vals.append(v)
        if ordered:
            ordered = all(last_vals[i] > last_vals[i+1] for i in range(len(last_vals)-1))

        slopes_ok = True
        for w in windows:
            v_now = ma[w].iloc[-1]
            v_prev = ma[w].iloc[-1 - slope_lookback] if len(ma[w]) > slope_lookback else np.nan
            if pd.isna(v_now) or pd.isna(v_prev) or v_now <= v_prev:
                slopes_ok = False
                break

        # è¿‘é«˜ï¼ˆä¸å¿…é¡»ï¼‰ï¼šæœ€è¿‘æ˜¯å¦åˆ› nhigh_lookback æ–°é«˜
        near_high = False
        high_val = rs.rolling(nhigh_lookback, min_periods=1).max().iloc[-1]
        if not pd.isna(high_val):
            # å…è®¸ä¸è¿‘é«˜å·®è· 1%
            near_high = (last >= 0.99 * high_val)

        score = 0.0
        score += 30 if above_all else 0
        score += 40 if ordered else 0
        score += 20 if slopes_ok else 0
        score += 10 if near_high else 0

        return {
            "score": round(score, 2),
            "flags": {
                "rs_above_all_ma": bool(above_all),
                "rs_ma_ordered": bool(ordered),
                "rs_ma_slopes_ok": bool(slopes_ok),
                "rs_near_high": bool(near_high),
            },
            "latest": {
                "rs": float(last),
                **{f"rs_ma{w}": float(ma[w].iloc[-1]) if not pd.isna(ma[w].iloc[-1]) else np.nan for w in windows},
                "rs_recent_high": float(high_val) if not pd.isna(high_val) else np.nan,
            },
            "windows": windows,
            "slope_lookback": slope_lookback,
            "nhigh_lookback": nhigh_lookback,
        }
    
    # è®¡ç®—RSåŠ¨é‡
    def rs_momentum(
        stock_close: pd.Series,
        bench_close: pd.Series,
        n: int = 20,
        method: str = "roc"
    ) -> pd.Series:
        """
        RS åŠ¨é‡ï¼šå¯¹ RS çº¿åšåŠ¨é‡ï¼ˆé»˜è®¤ ROCï¼‰ã€‚
        """
        rs = StockAnalyzer.compute_rs(stock_close, bench_close)
        if method == "roc":
            return rs / rs.shift(n) - 1.0
        elif method == "diff":
            return rs - rs.shift(n)
        else:
            raise ValueError("method must be 'roc' or 'diff'")

    def plot_moving_averages(self, colors=['red', 'blue', 'green']):
        if not hasattr(self, 'ma_data'):
            raise ValueError("è¯·å…ˆè°ƒç”¨ calculate_moving_averages æ–¹æ³•ï¼")
        x_axis = self.ma_data['date']
        plt.figure(figsize=(14, 8))
        for i, column in enumerate(self.ma_data.columns):
            if 'MA_' in column:
                plt.plot(x_axis, self.ma_data[column], label=column, color=colors[i % len(colors)], linewidth=1.5)
        step = 50
        selected_ticks = x_axis[::step]
        plt.xticks(selected_ticks, rotation=45)
        plt.xlabel('Date')
        plt.ylabel('Price')
        plt.title(f'{self.ticker} Moving Averages')
        plt.grid(True, linestyle='--', linewidth=0.2, alpha=1)
        plt.legend()
        plt.tight_layout()
        plt.show()
    
    def plot_all(self, data_ma, data_bbi, data_price, data_macd, data_kdj, data_shakeout, ticker, windows):
        # x_axis æ˜¯å½¢å¦‚ ['2020-01-01', ...] çš„å­—ç¬¦ä¸²åˆ—è¡¨
        x_axis = pd.to_datetime(data_ma['date'])

        fig = sp.make_subplots(
            rows=6, cols=2,
            specs=[[{}, {}],    # ç¬¬ä¸€è¡Œä¸¤åˆ—
                [{"colspan": 2}, None],  # ç¬¬äºŒè¡Œä¸€æ•´è¡Œï¼ˆè·¨2åˆ—ï¼‰
                [{"colspan": 2}, None],  # ç¬¬ä¸‰è¡Œä¸€æ•´è¡Œ
                [{"colspan": 2}, None],  # ç¬¬å››è¡Œä¸€æ•´è¡Œ
                [{}, {}],
                [{"colspan": 2}, None]], # ç¬¬äº”è¡Œä¸€æ•´è¡Œï¼ˆè·¨2åˆ—ï¼‰
            shared_xaxes=True,
            vertical_spacing=0.05,
            horizontal_spacing=0.1,
            subplot_titles=[
                f'MA {windows[0]} {windows[1]} {windows[2]}', 'BBI',
                'Avg & Close Price',
                'KDJ-J Highlighted Points',
                'MACD',
                'KDJ-J Highlighted Points -10~90', 'KDJ-J Highlighted Points-15~100',
                'Shakeout Monitoring'
            ]
        )

        fig.update_layout(
        xaxis3=dict(matches='x'),
        xaxis4=dict(matches='x'),
        xaxis5=dict(matches='x'),
        xaxis6=dict(matches='x')
    )

        # ç¬¬ä¸€è¡Œï¼Œå·¦å›¾ MA
        fig.add_trace(go.Scatter(x=x_axis, y=data_ma[f'MA_{windows[0]}'], name=f'MA_{windows[0]}', line=dict(color='orange')), row=1, col=1)
        fig.add_trace(go.Scatter(x=x_axis, y=data_ma[f'MA_{windows[1]}'], name=f'MA_{windows[1]}', line=dict(color='gray')), row=1, col=1)
        fig.add_trace(go.Scatter(x=x_axis, y=data_ma[f'MA_{windows[2]}'], name=f'MA_{windows[2]}', line=dict(color='green')), row=1, col=1)

        # ç¬¬ä¸€è¡Œï¼Œå³å›¾ BBI
        fig.add_trace(go.Scatter(x=x_axis, y=data_bbi['bbi'], name='BBI', line=dict(color='orange')), row=1, col=2)

        # ç¬¬äºŒè¡Œï¼Œæ•´è¡Œ price
        fig.add_trace(go.Scatter(x=x_axis, y=data_price['avg_price'], name='avg_price', line=dict(color='gray')), row=2, col=1)
        fig.add_trace(go.Scatter(x=x_axis, y=data_price['close_price'], name='close_price', line=dict(color='green')), row=2, col=1)

        # ç¬¬ä¸‰è¡Œï¼Œæ•´è¡Œ KDJ-J + é«˜äº®ç‚¹
        fig.add_trace(go.Scatter(x=x_axis, y=data_kdj['J'], name='KDJ-J', line=dict(color='gray')), row=3, col=1)

        mask_low = data_kdj['J'] <= -5
        fig.add_trace(go.Scatter(
            x=x_axis[mask_low],
            y=data_kdj['J'][mask_low],
            mode='markers+text',
            name='J <= -5',
            marker=dict(color='red', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_low]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=3, col=1)

        mask_high = data_kdj['J'] > 80
        fig.add_trace(go.Scatter(
            x=x_axis[mask_high],
            y=data_kdj['J'][mask_high],
            mode='markers+text',
            name='J > 80',
            marker=dict(color='green', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_high]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=3, col=1)

        # ç¬¬å››è¡Œï¼Œæ•´è¡Œ MACD
        fig.add_trace(go.Scatter(x=x_axis, y=data_macd['DIF'], name='DIF', line=dict(color='green')), row=4, col=1)
        fig.add_trace(go.Scatter(x=x_axis, y=data_macd['DEA'], name='DEA', line=dict(color='gray')), row=4, col=1)

        # ç¬¬äº”è¡Œï¼Œå·¦å›¾ -10ï½90
        fig.add_trace(go.Scatter(x=x_axis, y=data_kdj['J'], name='KDJ-J', line=dict(color='gray')), row=5, col=1)

        mask_low = data_kdj['J'] <= -10
        fig.add_trace(go.Scatter(
            x=x_axis[mask_low],
            y=data_kdj['J'][mask_low],
            mode='markers+text',
            name='J <= -10',
            marker=dict(color='red', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_low]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=5, col=1)

        mask_high = data_kdj['J'] > 90
        fig.add_trace(go.Scatter(
            x=x_axis[mask_high],
            y=data_kdj['J'][mask_high],
            mode='markers+text',
            name='J > 90',
            marker=dict(color='green', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_high]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=5, col=1)

        # ç¬¬äº”è¡Œï¼Œå³å›¾ -15ï½100
        fig.add_trace(go.Scatter(x=x_axis, y=data_kdj['J'], name='KDJ-J', line=dict(color='gray')), row=5, col=2)

        mask_low = data_kdj['J'] <= -15
        fig.add_trace(go.Scatter(
            x=x_axis[mask_low],
            y=data_kdj['J'][mask_low],
            mode='markers+text',
            name='J <= -15',
            marker=dict(color='red', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_low]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=5, col=1)

        mask_high = data_kdj['J'] > 100
        fig.add_trace(go.Scatter(
            x=x_axis[mask_high],
            y=data_kdj['J'][mask_high],
            mode='markers+text',
            name='J > 100',
            marker=dict(color='green', size=8),
            text=[f'{v:.1f}' for v in data_kdj['J'][mask_high]],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=5, col=2)

        # ç¬¬å…­è¡Œï¼Œæ•´è¡Œ shakeout monitoring
        fig.add_trace(go.Scatter(x=x_axis, y=data_shakeout['çŸ­æœŸ'], name='çŸ­æœŸ', line=dict(color='green')), row=6, col=1)
        fig.add_trace(go.Scatter(x=x_axis, y=data_shakeout['é•¿æœŸ'], name='é•¿æœŸ', line=dict(color='red')), row=6, col=1)

        # æ·»åŠ æ©ç 
        mask = (data_shakeout['çŸ­æœŸ'] < 20) & (data_shakeout['é•¿æœŸ'] > 60)

        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ x å’Œ y å€¼
        x_highlight = x_axis[mask]
        y_highlight = data_shakeout['çŸ­æœŸ'][mask]
        # æ·»åŠ é«˜äº®ç‚¹
        fig.add_trace(go.Scatter(
            x=x_highlight,
            y=y_highlight,
            mode='markers+text',
            name='çŸ­æœŸ<20 & é•¿æœŸ>60',
            marker=dict(color='cyan', size=10, symbol='circle'),
            text=[f'{v:.1f}' for v in y_highlight],
            textposition='top center',
            textfont=dict(color='blue')
        ), row=6, col=1)

        # åœ¨ç¬¬å…­è¡Œå­å›¾ï¼ˆrow=6, col=1ï¼‰ä¸Šç»˜åˆ¶ y=20, 60, 80 ä¸‰æ¡æ¨ªçº¿ çº¢çº¿åœ¨60 80ä¹‹é—´ ç™½çº¿åœ¨20ä»¥ä¸‹
        for y_val in [60, 80]:
            fig.add_shape(
                type="line",
                x0=x_axis.min(),
                x1=x_axis.max(),
                y0=y_val,
                y1=y_val,
                line=dict(color="green", width=3, dash="solid"),
                xref="x8",  # row=6 col=1 çš„ subplot x è½´
                yref="y8"   # row=6 col=1 çš„ subplot y è½´
            )

        fig.add_shape(
                type="line",
                x0=x_axis.min(),
                x1=x_axis.max(),
                y0=20,
                y1=20,
                line=dict(color="yellow", width=3, dash="solid"),
                xref="x8",  # row=6 col=1 çš„ subplot x è½´
                yref="y8"   # row=6 col=1 çš„ subplot y è½´
            )
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            height=1200,
            width=1400,
            title=f'{ticker}',
            showlegend=True,
            plot_bgcolor='rgba(0,0,0,1)',
            template='plotly_white'
        )

        fig.show()
    
    def save_moving_averages(self, filename=None):
        if not hasattr(self, 'ma_data'):
            raise ValueError("è¯·å…ˆè°ƒç”¨ calculate_moving_averages æ–¹æ³•ï¼")
        filename = filename or f'{self.ticker}_moving_averages.csv'
        self.ma_data.to_csv(filename, index=False)
        print(f"æ•°æ®å·²ä¿å­˜è‡³ï¼š{filename}")

# è®¡ç®—ä¹°å…¥å–å‡ºä¿¡å·
class StockMonitor:
    '''
    ç›‘æ§ä¹°å…¥å–å‡ºä¿¡å·
    '''
    def __init__(self, ticker, file_path,  file_volume_path, start_date=None, end_date=None, lookback_period=10, min_signal_count=3):
        self.ticker = ticker
        self.file_path = file_path
        self.file_volume_path = file_volume_path
        self.start_date = start_date
        self.end_date = end_date
        self.lookback_period = lookback_period # è¿ç»­nå¤©å†…å‡ºç°å•é’ˆä¸‹20çš„ä¿¡å·
        self.min_signal_count = min_signal_count # å‡ºç°næ¬¡å•é’ˆä¸‹20çš„ä¿¡å·
    
    def fastdown_J(self):
        '''
        ä¹°å…¥é€»è¾‘
        '''
        analyzer = StockAnalyzer(self.ticker, self.file_path)
        data_kdj = analyzer.calculate_kdj()
        label = False
        if (data_kdj['J'].iloc[-3] - data_kdj['J'].iloc[-1]) >= 70 and data_kdj['J'].iloc[-1] < 10:
            label = True
        '''
        label = all(
        any([
            (data_kdj['J'].iloc[-1] < 10 and data_kdj['J'].iloc[period] > 70),  
            (data_kdj['J'].iloc[-1] < 5 and data_kdj['J'].iloc[period] > 65),  
            (data_kdj['J'].iloc[-1] < 0 and data_kdj['J'].iloc[period] > 60) 
        ])
        for period in [-1, -2, -3] )
        '''
        print(f"{self.ticker}:Jå€¼æ˜¯å¦å¿«é€Ÿä¸‹é™ï¼š{'trueâœ…' if label else 'falseâŒ'}ï¼Œæœ€è¿‘3ï¸âƒ£å¤©çš„Jå€¼ï¼š{round(data_kdj['J'].iloc[-3],1)}ï¼Œ{round(data_kdj['J'].iloc[-2],1)}ï¼Œ{round(data_kdj['J'].iloc[-1],1)}")

        return label

    def continuous_shakeout(self):
        '''
        ä¹°å…¥é€»è¾‘
        '''
        analyzer = StockAnalyzer(self.ticker, self.file_path)
        data_shakeout = analyzer.calculate_shakeout()
        label = False
        label = all(
        any([
            data_shakeout.iloc[period].get("å››çº¿å½’é›¶ä¹°", False) == 1,
            data_shakeout.iloc[period].get("ç™½çº¿ä¸‹20ä¹°", False) == 1,
            data_shakeout.iloc[period].get("ç™½ç©¿çº¢çº¿ä¹°", False) == 1,
            data_shakeout.iloc[period].get("ç™½ç©¿é»„çº¿ä¹°", False) == 1,
            data_shakeout.iloc[period].get("ç™½çº¿ä¸‹20ä¹°_å°V", False) == 1
        ])
        for period in [-1, -2] )

        return label

    def check_signal_frequency(self):
        '''
        ä¹°å…¥é€»è¾‘ï¼Œæ£€æŸ¥æœ€è¿‘10å¤©å†…æ˜¯å¦è‡³å°‘æœ‰3ä¸ªå‘¨æœŸæ»¡è¶³ä»»æ„ä¹°å…¥ä¿¡å·
        '''
        analyzer = StockAnalyzer(self.ticker, self.file_path)
        data_shakeout = analyzer.calculate_shakeout()
        signal_count = 0
        for period in range(-1, -self.lookback_period-1, -1): 
            if any([
                data_shakeout.iloc[period].get("å››çº¿å½’é›¶ä¹°", 0) == 1,
                data_shakeout.iloc[period].get("ç™½çº¿ä¸‹20ä¹°", 0) == 1,
                data_shakeout.iloc[period].get("ç™½ç©¿çº¢çº¿ä¹°", 0) == 1,
                data_shakeout.iloc[period].get("ç™½ç©¿é»„çº¿ä¹°", 0) == 1,
                data_shakeout.iloc[period].get("ç™½çº¿ä¸‹20ä¹°_å°V", 0) == 1
            ]):
                signal_count += 1
                if signal_count >= self.min_signal_count:  # è¾¾åˆ°æœ€å°ä¿¡å·æ•°å°±æå‰è¿”å›
                    return True
        return signal_count >= self.min_signal_count

    def bs_abnormal_monitor(self):
        '''
        * ä¹°å…¥ã€å–å‡ºé€»è¾‘
        * ç›‘æ§å¼‚å¸¸äº¤æ˜“é‡ã€ä»·æ ¼ã€ä¹°å–ç¬”æ•°ï¼Œæ¯”å¦‚å½“æ—¥ç»¿çº¿ï¼Œä½†æ˜¯ä¹°å…¥ç¬”æ•°å¤§äºå–å‡ºç¬”æ•°ï¼Œå¯èƒ½æ˜¯æœ‰äººåœ¨ä½ä½æ”¶ç­¹ç 
        * å¼€ç›˜æ”¶ç›˜ä»·æ ¼æ˜¯ä»000001.csvï¼ˆå†å²ä»·æ ¼ï¼‰æ–‡ä»¶ä¸­è·å–çš„ï¼Œå¼€ç›˜æ”¶ç›˜æ€»ä»·å’Œæ€»é‡æ˜¯ä»000001_volume.csvï¼ˆåªæœ‰æ¯å¤©æœ€æ–°çš„ä»·æ ¼ï¼‰æ–‡ä»¶ä¸­è·å–çš„ï¼Œå¦‚æœæƒ³çœ‹å†å²æ•°æ®å¯ä»¥å»é€šè¾¾ä¿¡å¯¼å‡º
        '''
        # è·å–çš„æ˜¯å½“å¤©æœ€æ–°çš„æ•°æ®
        df = getData.read_from_csv(self.file_volume_path)
        sell_list = []
        buy_list = []
        sellprice_amount = 0
        buyprice_amount = 0
        sellvolume_amount = 0
        buyvolume_amount = 0
        label = False
        abnormal_type = 'none'
        for _, row in df.iterrows():
            record = {
                'æˆäº¤é‡‘é¢': row['æˆäº¤é‡‘é¢'],
                'æˆäº¤é‡': row['æˆäº¤é‡'],
                'æ€§è´¨': row['æ€§è´¨']
            }
            if row['æ€§è´¨'] == 'å–ç›˜':
                sell_list.append(record)
                sellprice_amount += int(row['æˆäº¤é‡‘é¢'])
                sellvolume_amount += int(row['æˆäº¤é‡'])
            elif row['æ€§è´¨'] == 'ä¹°ç›˜':
                buy_list.append(record)
                buyprice_amount += int(row['æˆäº¤é‡‘é¢'])
                buyvolume_amount += int(row['æˆäº¤é‡'])
        # è·å–å†å²ä¸Šæœ€æ–°çš„æ•°æ®
        analyzer = StockAnalyzer(self.ticker, self.file_path)
        price_dict = analyzer.calculate_price()
        open_price = price_dict['open_price'].iloc[-1]
        close_price = price_dict['close_price'].iloc[-1]

        if (close_price < open_price) and (buyvolume_amount > sellvolume_amount):
            print(f"â—ï¸å½“æ—¥ç»¿çº¿ğŸ“‰ï¼Œä½†æ˜¯ä¹°å…¥é‡å¤§äºå–å‡ºé‡ï¼Œå¯èƒ½æ˜¯æœ‰äººå·å·åœ¨ä½ä½æ”¶ç­¹ç â—ï¸")
            label = True
            abnormal_type = 'buy'
        elif(close_price > open_price) and (buyvolume_amount < sellvolume_amount):
            print(f"â—ï¸å½“æ—¥çº¢çº¿ğŸ“ˆï¼Œä½†æ˜¯ä¹°å…¥é‡å°äºå–å‡ºé‡ï¼Œå¯èƒ½æ˜¯æœ‰äººå·å·åœ¨é«˜ä½å–ç­¹ç â—ï¸")
            label = True
            abnormal_type = 'sell'
        else:
            print(f"æˆäº¤é‡æ— å¼‚å¸¸")

        if (close_price < open_price) and (buyprice_amount > sellprice_amount):
            print(f"â—ï¸å½“æ—¥ç»¿çº¿ğŸ“‰ï¼Œä½†æ˜¯ä¹°å…¥æ€»é¢å¤§äºå–å‡ºæ€»é¢ï¼Œå¯èƒ½æ˜¯æœ‰äººå·å·åœ¨ä½ä½æ”¶ç­¹ç â—ï¸")
            label = True
            abnormal_type = 'buy'
        elif(close_price > open_price) and (buyprice_amount < sellprice_amount):
            print(f"â—ï¸å½“æ—¥çº¢çº¿ğŸ“ˆï¼Œä½†æ˜¯ä¹°å…¥æ€»é¢å°äºå–å‡ºæ€»é¢ï¼Œå¯èƒ½æ˜¯æœ‰äººå·å·åœ¨é«˜ä½å–ç­¹ç â—ï¸")
            label = True
            abnormal_type = 'sell'
        else:
            print(f"æˆäº¤æ€»é¢æ— å¼‚å¸¸")

        # è·å–æ€»å¸‚å€¼å’Œæ€»è‚¡æœ¬
        market_cap, share_cap = getData.download_total_cap(self.ticker)

        print(f"å½“æ—¥å¼€ç›˜ä»·ï¼š{open_price}ï¼Œæ”¶ç›˜ä»·ï¼š{close_price}ï¼Œ {'ğŸ“ˆ' if close_price > open_price else 'ğŸ“‰'}ï¼Œ å–å‡ºæ€»é¢ï¼š{sellprice_amount}={int_to_chinese_num(sellprice_amount)}ï¼Œä¹°å…¥æ€»é¢ï¼š{buyprice_amount}={int_to_chinese_num(buyprice_amount)}ï¼Œå‡€ä¹°å…¥æ€»é¢ï¼š{buyprice_amount-sellprice_amount}={int_to_chinese_num(buyprice_amount-sellprice_amount)}ï¼Œå–å‡ºæ€»é‡ï¼š{sellvolume_amount}={int_to_chinese_num(sellvolume_amount)}ï¼Œä¹°å…¥æ€»é‡ï¼š{buyvolume_amount}={int_to_chinese_num(buyvolume_amount)}ï¼Œå‡€ä¹°å…¥æ€»é‡ï¼š{buyvolume_amount-sellvolume_amount}={int_to_chinese_num(buyvolume_amount-sellvolume_amount)}")
        print(f"å½“å‰äº¤æ˜“å æ€»è‚¡æœ¬æ¯”é‡:{round(abs(buyprice_amount-sellprice_amount) / int(share_cap),3)}ï¼Œå æ€»å¸‚å€¼æ¯”é‡ä¸º:{round(abs(buyprice_amount-sellprice_amount) / int(market_cap),3)}")
        return {'open_price': open_price, 'close_price': close_price, 'sellprice_amount': sellprice_amount, 'buyprice_amount': buyprice_amount, 'sellvolume_amount': sellvolume_amount
                , 'buyvolume_amount': buyvolume_amount, 'label':label, 'abnormal_type':abnormal_type, 'market_cap_percentage':round(abs(buyprice_amount-sellprice_amount) / int(share_cap),3)
                , 'share_cap_percentage':round(abs(buyprice_amount-sellprice_amount) / int(market_cap),3)}

    def below_bbi_monitor(self):
        '''
        å–å‡ºä¿¡å·ï¼Œè·Œç ´BBIä¸¤æ ¹å–å‡ºä¿¡å·ï¼Œå³æ”¶ç›˜ä»·ä½äºBBI
        '''
        # è·å–çš„æ˜¯å½“å¤©æœ€æ–°çš„ä»·æ ¼æ•°æ®
        df = getData.read_from_csv(self.file_path)

        analyzer = StockAnalyzer(self.ticker, self.file_path)
        bbi = analyzer.calculate_bbi()

        bbi_label = False

        if (df['å¼€ç›˜'].iloc[-1] > bbi['bbi'].iloc[-1] > df['æ”¶ç›˜'].iloc[-1]) and (df['å¼€ç›˜'].iloc[-2] > bbi['bbi'].iloc[-2] > df['æ”¶ç›˜'].iloc[-2]):
            bbi_label = True
            print(f"â—ï¸è·Œç ´BBIä¸¤æ ¹å–å‡ºä¿¡å·â—ï¸")
        else:
            print(f"æœªè·Œç ´BBIä¸¤æ ¹å–å‡ºä¿¡å·")

        return bbi_label

    def twin_tails_monitor(self):
        '''
        åŒé©¬å°¾ï¼Œæ ¹æ®ä»·æ ¼åˆ¤æ–­----çœ‹ä¸€ä¸‹è¿™ä¸ªé€»è¾‘èƒ½ä¸èƒ½ç­›é€‰å‡ºæ¥å¨œå¨œçš„å›¾å½¢

        æ£€æŸ¥DataFrameä¸­æœ€è¿‘periodä¸ªäº¤æ˜“æ—¥æ˜¯å¦ç¬¦åˆä»¥ä¸‹æ¨¡å¼ï¼š
        1. åªæœ‰ä¸¤å¤©è¾¾åˆ°æœ€é«˜ä»·ï¼Œä¸”å·®å€¼åœ¨1%ä»¥å†…ï¼›
        2. è¿™ä¸¤å¤©ä¹‹é—´ç›¸å·®15å¤©ä»¥ä¸Šï¼›
        3. å‘¨æœŸå†…æœ€é«˜ä»·å’Œæœ€ä½ä»·è½å·®è¶…è¿‡30%ã€‚

        å‚æ•°:
            df (pd.DataFrame): åŒ…å« 'æ—¥æœŸ', 'æœ€é«˜', 'æœ€ä½' ä¸‰åˆ—
            period (int): æ£€æŸ¥å‘¨æœŸï¼ˆé»˜è®¤60å¤©ï¼‰

        è¿”å›:
            bool: æ˜¯å¦æ»¡è¶³æ¡ä»¶
        '''
        period_days_60 = 60 # è®¾ç½®è®¡ç®—å‘¨æœŸä¸º60å¤©

        df = getData.read_from_csv(self.file_path)
        required_cols = {'æ—¥æœŸ','æœ€é«˜ä»·','æœ€ä½ä»·'}
        if not required_cols.issubset(df.columns):
            raise ValueError(f"è¾“å…¥DataFrameå¿…é¡»åŒ…å«åˆ—ï¼š{required_cols}")
        
        recent_df_60 = df.tail(period_days_60).copy()

        if recent_df_60.shape[0] < period_days_60:
            print("æ•°æ®ä¸è¶³æŒ‡å®šå‘¨æœŸï¼Œè·³è¿‡æ£€æŸ¥ã€‚")
            return False

        # æœ€é«˜ä»·å’Œæœ€ä½ä»·
        highest_price_60 = recent_df_60['æœ€é«˜ä»·'].max()
        lowest_price_60 = recent_df_60['æœ€ä½ä»·'].min()

        # è½å·® > 15%
        if (highest_price_60 - lowest_price_60) / lowest_price_60 < 0.15:
            return False
        
        # å–ç¬¬äºŒé«˜ï¼Œåˆ¤æ–­ä¸æœ€é«˜ä»·çš„å·®è·
        second_high = recent_df_60['æœ€é«˜ä»·'].nlargest(2).iloc[1]
        diff_pct = abs(highest_price_60 - second_high) / highest_price_60
        if diff_pct > 0.05:
            return False
        
        # æ‰¾å‡ºè¾¾åˆ°æœ€é«˜ä»·çš„è¡Œ
        highest_rows = recent_df_60[recent_df_60['æœ€é«˜ä»·'] == highest_price_60]
        # ä¸¤ä¸ªæœ€é«˜ä»·çš„æ—¥æœŸé—´éš”è¦è¶…è¿‡15å¤©
        day_diff = abs((highest_rows['æ—¥æœŸ'].iloc[1] - highest_rows['æ—¥æœŸ'].iloc[0]).days)
        if day_diff <= 5:
            return False
        
        return True
    
    def position_building_monitor(self):
        '''
        å»ºä»“æ³¢ï¼Œå‡†å¤‡æ’…å°åœŸåŒ…ï¼Œè¿ç»­7å¤©åŠä»¥ä¸Šå°çº¢æˆ–è€…14å¤©å†…çº¢çš„å ä¸€å¤šåŠ
        '''
        df = getData.read_from_csv(self.file_path)
        # æ¡ä»¶1ç›¸å…³å¸ƒå°”åºåˆ—ï¼šæ”¶ç›˜é«˜äºå¼€ç›˜ï¼Œä¸”æŒ¯å¹…ï¼ˆhigh-lowï¼‰/open < 5%
        condition1 = (df['æ”¶ç›˜'] > df['å¼€ç›˜']) & ((df['æœ€é«˜'] - df['æœ€ä½']) / df['æœ€ä½'] < 0.05)
        # æ¡ä»¶2ï¼š14 æ—¥çª—å£å†…ï¼Œæ”¶ç›˜é«˜äºå¼€ç›˜çš„å¤©æ•° >= 10
        condition2 = (df['æ”¶ç›˜'] > df['å¼€ç›˜'])

        # æ¡ä»¶ 1ï¼šæœ€è¿‘è¿ç»­ 5 å¤©åŠä»¥ä¸Šæ»¡è¶³ cond1
        consecutive = 0
        for val in reversed(condition1.tolist()):  # ä»æœ€è¿‘æ—¥æœŸå‘å‰çœ‹
            if val:
                consecutive += 1
            else:
                break
        if consecutive >= 5:
            return True

        # ----------------------
        # æ¡ä»¶ 2ï¼šæœ€è¿‘ 14 ä¸ªäº¤æ˜“æ—¥å†…æœ‰ 10 å¤©ä»¥ä¸Šæ»¡è¶³ cond2
        if condition2.tail(14).sum() >= 10:
            return True

        return False
    
    def heavy_cannos_monitor(self):
        '''
        ä¸¤é—¨é‡ç‚®ï¼Œå–7å¤©ä¸º1ä¸ªå‘¨æœŸ
        '''
        df = getData.read_from_csv(self.file_path)
        df_volume = getData.read_from_csv(self.file_volume_path)
        period_df = df.iloc[-7:].copy()
        period_df_volume = df_volume.iloc[-7:].copy()

        today = df.iloc[-1]
        today_volume = df_volume.iloc[-1]

        today_high = today['æœ€é«˜ä»·']
        today_low = today['æœ€ä½ä»·']
        today_volume_amount = today_volume['æˆäº¤é‡‘é¢']
    
        for i in range(len(period_df) - 1):  # æœ€åä¸€è¡Œæ˜¯ä»Šå¤©ï¼Œä¸æ¯”è¾ƒ
            day = period_df.iloc[i]
            day_volume = period_df_volume.iloc[i]
            
            # åˆ¤æ–­ä»·æ ¼ä¸æˆäº¤é‡çš„ç›¸ä¼¼æ€§
            high_similar = abs(day['æœ€é«˜ä»·'] - today_high) / today_high <= 0.05
            low_similar = abs(day['æœ€ä½ä»·'] - today_low) / today_low <= 0.05
            volume_similar = abs(day_volume['æˆäº¤é‡‘é¢'] - today_volume_amount) / today_volume_amount <= 0.2
            
            if high_similar and low_similar and volume_similar:
                # æ‰¾å‡ºè¿™ä¸¤å¤©ä¸­è¾ƒä½çš„æˆäº¤é‡
                vol_min = min(day_volume['æˆäº¤é‡‘é¢'], today_volume_amount)
                
                # è¿™ä¸¤å¤©ä¹‹é—´çš„æ‰€æœ‰å¤©çš„æˆäº¤é‡å¿…é¡»éƒ½ä½äºè¿™ä¸¤å¤©çš„æœ€å°æˆäº¤é‡ï¼Œä¸ä¸€å®šæ˜¯å®Œå…¨å°äºï¼Œå¯èƒ½ä¸­é—´çš„æˆäº¤é‡ç•¥å¤§äºæœ€å°çš„
                intermediate = period_df.iloc[i+1:-1]
                if all(intermediate['æˆäº¤é‡‘é¢'] <= vol_min) and all(intermediate['æœ€é«˜ä»·'] < today_high) and all(intermediate['æœ€ä½ä»·'] > today_low):
                    return True  # æ»¡è¶³æ¡ä»¶
    
        return False  # æ‰€æœ‰å¤©éƒ½ä¸æ»¡è¶³

    def tradeing_sideways(self):
        '''
        æ¨ªç›˜ç›‘æ§ï¼Œé‡‡ç”¨æ¯”è¾ƒ5å¤©å‘¨æœŸå†…æœ€é«˜ä»·å’Œæœ€ä½ä»·ï¼Œå¦‚æœæœ€é«˜ä»·å’Œæœ€ä½ä»·ç›¸å·®ä¸è¶…è¿‡10%ï¼Œåˆ™è®¤ä¸ºæ¨ªç›˜
        '''
        df = getData.read_from_csv(self.file_path)
        period_df = df.iloc[-5:].copy()
        highest_price = period_df['æœ€é«˜'].max()
        lowest_price = period_df['æœ€ä½'].min()
        if (highest_price - lowest_price) / lowest_price <= 0.1:
            return True

        return False

# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    
    ticker = '600036.SS'
    file_path = '/Users/lidongyang/Desktop/MyInvestStrategy/GridStrategy/data/000001.csv'  # æ›¿æ¢ä¸ºä½ çš„è·¯å¾„
    file_volume_path = '/Users/lidongyang/Desktop/MyInvestStrategy/GridStrategy/data/000001_volume.csv'


    analyzer = StockAnalyzer(ticker, file_path)
    ma = analyzer.calculate_moving_averages()
    bbi = analyzer.calculate_bbi()
    kdj = analyzer.calculate_kdj()
    macd = analyzer.calculate_macd()
    price = analyzer.calculate_price()
    shakeout = analyzer.calculate_shakeout()

    StockMonitor(ticker, file_path, file_volume_path).below_bbi_monitor()
    
        #analyzer.plot_all(ma, bbi, price, macd, kdj, shakeout, '000001', windows=[20, 30, 60, 120])
    
